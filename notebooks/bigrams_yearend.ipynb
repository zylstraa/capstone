{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad Day</td>\n",
       "      <td>Daniel Powter</td>\n",
       "      <td>Where is the moment we needed the most?\\nYou k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "      <td>The gyal dem Schillaci, Sean da Paul\\nSo me gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Promiscuous</td>\n",
       "      <td>Nelly Furtado</td>\n",
       "      <td>Am I throwin' you off?\\nNope\\nDidn't think so\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're Beautiful</td>\n",
       "      <td>James Blunt</td>\n",
       "      <td>My life is brilliant\\nMy life is brilliant, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hips Don't Lie</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>Ladies up in here tonight\\nNo fighting (We got...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              track          artist  \\\n",
       "0           Bad Day   Daniel Powter   \n",
       "1       Temperature       Sean Paul   \n",
       "2       Promiscuous  Nelly Furtado    \n",
       "3  You're Beautiful     James Blunt   \n",
       "4    Hips Don't Lie        Shakira    \n",
       "\n",
       "                                              lyrics  \n",
       "0  Where is the moment we needed the most?\\nYou k...  \n",
       "1  The gyal dem Schillaci, Sean da Paul\\nSo me gi...  \n",
       "2  Am I throwin' you off?\\nNope\\nDidn't think so\\...  \n",
       "3  My life is brilliant\\nMy life is brilliant, my...  \n",
       "4  Ladies up in here tonight\\nNo fighting (We got...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_data = pd.read_csv('../genius_lyrics.csv')\n",
    "lyric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = lyric_data['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom stop words:\n",
    "sw = ['oh','ooh','yeah','na','la','hey','like','da','whoa','uh','huh','doh','doo','ha','eh','ay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "#code from affordable housing q4 project:\n",
    "def get_word_frequency(df):\n",
    "    \n",
    "    word_vectorizer_unigram = CountVectorizer(\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer='word', \n",
    "        stop_words= text.ENGLISH_STOP_WORDS.union(sw), \n",
    "    )\n",
    "    \n",
    "    sparse_matrix = word_vectorizer_unigram.fit_transform(\n",
    "        lyrics.apply(\n",
    "            lambda sentence: \" \".join(\n",
    "                [word.strip(\"_\") for word in simple_preprocess(sentence.strip().strip(\"-\").replace(\"-\", \" \"))]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create frequency matrix\n",
    "    #frequencies = sum(sparse_matrix).toarray()[0]\n",
    "    frequencies = sparse_matrix.sum(axis=0) #.toarray()[0]\n",
    "    \n",
    "    # Create DF from frequency matrix\n",
    "    #result_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "    result_df_unigram = pd.DataFrame(frequencies.reshape(-1,1), index=word_vectorizer_unigram.get_feature_names(), columns=['frequency'])\n",
    "\n",
    "    \n",
    "    # Return sorted DF\n",
    "    return result_df_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>4747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>4611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>4202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>3905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>2855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cause</th>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanna</th>\n",
       "      <td>2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ain</th>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency\n",
       "don         4747\n",
       "know        4611\n",
       "love        4202\n",
       "just        4040\n",
       "got         3905\n",
       "baby        3267\n",
       "let         2855\n",
       "ll          2441\n",
       "cause       2413\n",
       "wanna       2262\n",
       "want        2203\n",
       "say         2113\n",
       "girl        2107\n",
       "ain         2099\n",
       "make        2067\n",
       "time        1806\n",
       "right       1690\n",
       "way         1611\n",
       "need        1537\n",
       "come        1471"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_frequency(lyrics).sort_values('frequency',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad Day</td>\n",
       "      <td>Daniel Powter</td>\n",
       "      <td>Where is the moment we needed the most?\\nYou k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "      <td>The gyal dem Schillaci, Sean da Paul\\nSo me gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Promiscuous</td>\n",
       "      <td>Nelly Furtado</td>\n",
       "      <td>Am I throwin' you off?\\nNope\\nDidn't think so\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're Beautiful</td>\n",
       "      <td>James Blunt</td>\n",
       "      <td>My life is brilliant\\nMy life is brilliant, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hips Don't Lie</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>Ladies up in here tonight\\nNo fighting (We got...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              track          artist  \\\n",
       "0           Bad Day   Daniel Powter   \n",
       "1       Temperature       Sean Paul   \n",
       "2       Promiscuous  Nelly Furtado    \n",
       "3  You're Beautiful     James Blunt   \n",
       "4    Hips Don't Lie        Shakira    \n",
       "\n",
       "                                              lyrics  \n",
       "0  Where is the moment we needed the most?\\nYou k...  \n",
       "1  The gyal dem Schillaci, Sean da Paul\\nSo me gi...  \n",
       "2  Am I throwin' you off?\\nNope\\nDidn't think so\\...  \n",
       "3  My life is brilliant\\nMy life is brilliant, my...  \n",
       "4  Ladies up in here tonight\\nNo fighting (We got...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_data = pd.read_csv('../genius_lyrics.csv')\n",
    "lyric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = lyric_data['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom stop words:\n",
    "sw = ['oh','ooh','yeah','na','la','hey','like','da','whoa','uh','huh','doh','doo','ha','eh','ay','ayy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "#code from affordable housing q4 project:\n",
    "def get_unigram(series):\n",
    "    \n",
    "    word_vectorizer_unigram = CountVectorizer(\n",
    "        ngram_range=(1, 1),\n",
    "        analyzer='word', \n",
    "        stop_words= text.ENGLISH_STOP_WORDS.union(sw), \n",
    "    )\n",
    "    \n",
    "    sparse_matrix = word_vectorizer_unigram.fit_transform(\n",
    "        lyrics.apply(\n",
    "            lambda sentence: \" \".join(\n",
    "                [word.strip(\"_\") for word in simple_preprocess(sentence.strip().strip(\"-\").replace(\"-\", \" \"))]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create frequency matrix\n",
    "    #frequencies = sum(sparse_matrix).toarray()[0]\n",
    "    frequencies = sparse_matrix.sum(axis=0) #.toarray()[0]\n",
    "    \n",
    "    # Create DF from frequency matrix\n",
    "    #result_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "    result_df_unigram = pd.DataFrame(frequencies.reshape(-1,1), \n",
    "                                     index=word_vectorizer_unigram.get_feature_names(), \n",
    "                                     columns=['frequency']).sort_values('frequency',ascending=False)\n",
    "\n",
    "    \n",
    "    # Return sorted DF\n",
    "    return result_df_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>4747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>4611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>4202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>3905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>2855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cause</th>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wanna</th>\n",
       "      <td>2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ain</th>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency\n",
       "don         4747\n",
       "know        4611\n",
       "love        4202\n",
       "just        4040\n",
       "got         3905\n",
       "baby        3267\n",
       "let         2855\n",
       "ll          2441\n",
       "cause       2413\n",
       "wanna       2262\n",
       "want        2203\n",
       "say         2113\n",
       "girl        2107\n",
       "ain         2099\n",
       "make        2067\n",
       "time        1806\n",
       "right       1690\n",
       "way         1611\n",
       "need        1537\n",
       "come        1471"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unigram(lyrics).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "#code from affordable housing q4 project:\n",
    "def get_bigram(series):\n",
    "    \n",
    "    word_vectorizer_bigram = CountVectorizer(\n",
    "        ngram_range=(2, 2),\n",
    "        analyzer='word', \n",
    "        stop_words= text.ENGLISH_STOP_WORDS.union(sw), \n",
    "    )\n",
    "    \n",
    "    sparse_matrix = word_vectorizer_bigram.fit_transform(\n",
    "        lyrics.apply(\n",
    "            lambda sentence: \" \".join(\n",
    "                [word.strip(\"_\") for word in simple_preprocess(sentence.strip().strip(\"-\").replace(\"-\", \" \"))]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create frequency matrix\n",
    "    #frequencies = sum(sparse_matrix).toarray()[0]\n",
    "    frequencies = sparse_matrix.sum(axis=0) #.toarray()[0]\n",
    "    \n",
    "    # Create DF from frequency matrix\n",
    "    #result_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "    result_df_bigram = pd.DataFrame(frequencies.reshape(-1,1), \n",
    "                                    index=word_vectorizer_bigram.get_feature_names(), \n",
    "                                    columns=['frequency']).sort_values('frequency',ascending=False)\n",
    "\n",
    "    \n",
    "    # Return sorted DF\n",
    "    return result_df_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>love love</th>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don know</th>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don wanna</th>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know know</th>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low low</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby baby</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shake shake</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don want</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just wanna</th>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve got</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woah woah</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don need</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby don</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work work</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want want</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr manhattan</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make feel</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let love</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don care</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come come</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              frequency\n",
       "love love           574\n",
       "don know            524\n",
       "don wanna           430\n",
       "know know           382\n",
       "low low             312\n",
       "baby baby           281\n",
       "shake shake         248\n",
       "don want            233\n",
       "just wanna          227\n",
       "ve got              222\n",
       "woah woah           200\n",
       "don need            194\n",
       "baby don            188\n",
       "work work           181\n",
       "want want           175\n",
       "dr manhattan        173\n",
       "make feel           168\n",
       "let love            166\n",
       "don care            161\n",
       "come come           156"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bigram(lyrics).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

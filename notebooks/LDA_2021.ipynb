{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.read_csv('../genius_lyrics21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = lyrics['lyrics'].tolist() #list of Unicode strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "\n",
    "#Removing stopwords:\n",
    "from sklearn.feature_extraction import text\n",
    "sw = ['oh','ooh','yeah','na','la','hey','like','da', 'feat',\n",
    "      'whoa','uh','huh','doh','doo','ha','eh','ay','ayy','ll','re','ve'] #removing sounds & contractions\n",
    "stop_words= text.ENGLISH_STOP_WORDS.union(sw)\n",
    "\n",
    "docs = [[token for token in doc if token not in stop_words] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zylst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zylst\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 2132\n",
      "Number of documents: 1362\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) #enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-05 17:03:11,363 : INFO : using autotuned alpha, starting with [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-06-05 17:03:11,364 : INFO : using serial LDA version on this node\n",
      "2021-06-05 17:03:11,367 : INFO : running online (multi-pass) LDA training, 3 topics, 20 passes over the supplied corpus of 1362 documents, updating model once every 1362 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2021-06-05 17:03:11,368 : INFO : PROGRESS: pass 0, at document #1362/1362\n",
      "2021-06-05 17:03:14,366 : WARNING : updated prior is not positive\n",
      "2021-06-05 17:03:14,366 : INFO : optimized alpha [0.33333334, 0.33333334, 0.33333334]\n",
      "2021-06-05 17:03:14,368 : INFO : topic #0 (0.333): 0.017*\"got\" + 0.015*\"nigga\" + 0.013*\"bitch\" + 0.013*\"let\" + 0.013*\"love\" + 0.012*\"ft\" + 0.011*\"shit\" + 0.010*\"ain\" + 0.009*\"anderson\" + 0.008*\"way\"\n",
      "2021-06-05 17:03:14,369 : INFO : topic #1 (0.333): 0.018*\"mind\" + 0.012*\"day\" + 0.012*\"got\" + 0.010*\"long\" + 0.010*\"just\" + 0.010*\"way\" + 0.009*\"life\" + 0.009*\"tryin\" + 0.009*\"cause\" + 0.009*\"wanna\"\n",
      "2021-06-05 17:03:14,370 : INFO : topic #2 (0.333): 0.015*\"ain\" + 0.015*\"got\" + 0.012*\"love\" + 0.012*\"just\" + 0.010*\"baby\" + 0.010*\"make\" + 0.009*\"nigga\" + 0.009*\"need\" + 0.009*\"time\" + 0.008*\"bitch\"\n",
      "2021-06-05 17:03:14,371 : INFO : topic diff=1.716190, rho=1.000000\n",
      "2021-06-05 17:03:14,375 : INFO : PROGRESS: pass 1, at document #1362/1362\n",
      "2021-06-05 17:03:15,165 : INFO : optimized alpha [0.14842016, 0.09976478, 0.16711923]\n",
      "2021-06-05 17:03:15,167 : INFO : topic #0 (0.148): 0.018*\"got\" + 0.017*\"nigga\" + 0.014*\"bitch\" + 0.013*\"let\" + 0.012*\"love\" + 0.011*\"ft\" + 0.011*\"shit\" + 0.010*\"ain\" + 0.009*\"anderson\" + 0.008*\"just\"\n",
      "2021-06-05 17:03:15,168 : INFO : topic #1 (0.100): 0.019*\"mind\" + 0.013*\"got\" + 0.011*\"day\" + 0.010*\"just\" + 0.010*\"long\" + 0.010*\"way\" + 0.009*\"wanna\" + 0.009*\"life\" + 0.009*\"cause\" + 0.009*\"tryin\"\n",
      "2021-06-05 17:03:15,169 : INFO : topic #2 (0.167): 0.015*\"ain\" + 0.014*\"got\" + 0.012*\"love\" + 0.012*\"just\" + 0.010*\"baby\" + 0.010*\"need\" + 0.009*\"make\" + 0.009*\"que\" + 0.009*\"time\" + 0.008*\"let\"\n",
      "2021-06-05 17:03:15,169 : INFO : topic diff=0.252619, rho=0.577350\n",
      "2021-06-05 17:03:15,172 : INFO : PROGRESS: pass 2, at document #1362/1362\n",
      "2021-06-05 17:03:16,374 : INFO : optimized alpha [0.11584169, 0.08626397, 0.12801994]\n",
      "2021-06-05 17:03:16,377 : INFO : topic #0 (0.116): 0.018*\"nigga\" + 0.018*\"got\" + 0.014*\"bitch\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"shit\" + 0.011*\"ft\" + 0.010*\"ain\" + 0.009*\"anderson\" + 0.008*\"just\"\n",
      "2021-06-05 17:03:16,378 : INFO : topic #1 (0.086): 0.019*\"mind\" + 0.013*\"got\" + 0.011*\"day\" + 0.011*\"just\" + 0.010*\"way\" + 0.010*\"long\" + 0.010*\"wanna\" + 0.009*\"cause\" + 0.009*\"life\" + 0.009*\"tell\"\n",
      "2021-06-05 17:03:16,380 : INFO : topic #2 (0.128): 0.015*\"ain\" + 0.013*\"got\" + 0.013*\"love\" + 0.012*\"just\" + 0.011*\"baby\" + 0.010*\"need\" + 0.009*\"que\" + 0.009*\"make\" + 0.009*\"time\" + 0.008*\"let\"\n",
      "2021-06-05 17:03:16,381 : INFO : topic diff=0.184139, rho=0.500000\n",
      "2021-06-05 17:03:16,384 : INFO : PROGRESS: pass 3, at document #1362/1362\n",
      "2021-06-05 17:03:17,493 : INFO : optimized alpha [0.10040153, 0.078549996, 0.10956787]\n",
      "2021-06-05 17:03:17,496 : INFO : topic #0 (0.100): 0.019*\"nigga\" + 0.019*\"got\" + 0.014*\"bitch\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"shit\" + 0.011*\"ft\" + 0.010*\"ain\" + 0.009*\"anderson\" + 0.008*\"just\"\n",
      "2021-06-05 17:03:17,497 : INFO : topic #1 (0.079): 0.018*\"mind\" + 0.013*\"got\" + 0.011*\"just\" + 0.011*\"day\" + 0.010*\"way\" + 0.010*\"wanna\" + 0.010*\"long\" + 0.009*\"cause\" + 0.009*\"life\" + 0.009*\"tell\"\n",
      "2021-06-05 17:03:17,499 : INFO : topic #2 (0.110): 0.015*\"ain\" + 0.013*\"love\" + 0.012*\"got\" + 0.012*\"just\" + 0.011*\"baby\" + 0.010*\"need\" + 0.010*\"que\" + 0.009*\"make\" + 0.009*\"time\" + 0.008*\"good\"\n",
      "2021-06-05 17:03:17,500 : INFO : topic diff=0.145990, rho=0.447214\n",
      "2021-06-05 17:03:17,504 : INFO : PROGRESS: pass 4, at document #1362/1362\n",
      "2021-06-05 17:03:18,589 : INFO : optimized alpha [0.09103449, 0.07377425, 0.09883247]\n",
      "2021-06-05 17:03:18,592 : INFO : topic #0 (0.091): 0.020*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"shit\" + 0.011*\"ft\" + 0.011*\"ain\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:18,594 : INFO : topic #1 (0.074): 0.018*\"mind\" + 0.014*\"got\" + 0.011*\"just\" + 0.010*\"day\" + 0.010*\"way\" + 0.010*\"wanna\" + 0.010*\"long\" + 0.009*\"tell\" + 0.009*\"cause\" + 0.009*\"life\"\n",
      "2021-06-05 17:03:18,595 : INFO : topic #2 (0.099): 0.015*\"ain\" + 0.012*\"love\" + 0.012*\"got\" + 0.012*\"just\" + 0.011*\"baby\" + 0.010*\"need\" + 0.010*\"que\" + 0.009*\"make\" + 0.009*\"time\" + 0.008*\"young\"\n",
      "2021-06-05 17:03:18,595 : INFO : topic diff=0.119769, rho=0.408248\n",
      "2021-06-05 17:03:18,599 : INFO : PROGRESS: pass 5, at document #1362/1362\n",
      "2021-06-05 17:03:19,459 : INFO : optimized alpha [0.08417735, 0.07096318, 0.09158191]\n",
      "2021-06-05 17:03:19,460 : INFO : topic #0 (0.084): 0.020*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"let\" + 0.012*\"shit\" + 0.012*\"love\" + 0.011*\"ft\" + 0.011*\"ain\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:19,461 : INFO : topic #1 (0.071): 0.018*\"mind\" + 0.014*\"got\" + 0.011*\"just\" + 0.010*\"way\" + 0.010*\"day\" + 0.010*\"wanna\" + 0.010*\"tell\" + 0.010*\"long\" + 0.009*\"cause\" + 0.009*\"love\"\n",
      "2021-06-05 17:03:19,461 : INFO : topic #2 (0.092): 0.015*\"ain\" + 0.012*\"love\" + 0.012*\"got\" + 0.012*\"just\" + 0.011*\"baby\" + 0.010*\"need\" + 0.010*\"que\" + 0.009*\"time\" + 0.008*\"make\" + 0.008*\"young\"\n",
      "2021-06-05 17:03:19,462 : INFO : topic diff=0.101104, rho=0.377964\n",
      "2021-06-05 17:03:19,464 : INFO : PROGRESS: pass 6, at document #1362/1362\n",
      "2021-06-05 17:03:19,895 : INFO : optimized alpha [0.07912142, 0.06859363, 0.08580261]\n",
      "2021-06-05 17:03:19,897 : INFO : topic #0 (0.079): 0.021*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"let\" + 0.013*\"shit\" + 0.012*\"love\" + 0.011*\"ft\" + 0.011*\"ain\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:19,898 : INFO : topic #1 (0.069): 0.018*\"mind\" + 0.014*\"got\" + 0.011*\"just\" + 0.010*\"way\" + 0.010*\"wanna\" + 0.010*\"day\" + 0.010*\"tell\" + 0.010*\"love\" + 0.010*\"long\" + 0.009*\"cause\"\n",
      "2021-06-05 17:03:19,899 : INFO : topic #2 (0.086): 0.015*\"ain\" + 0.012*\"love\" + 0.012*\"just\" + 0.012*\"got\" + 0.011*\"baby\" + 0.010*\"need\" + 0.010*\"que\" + 0.009*\"time\" + 0.008*\"young\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:19,900 : INFO : topic diff=0.086058, rho=0.353553\n",
      "2021-06-05 17:03:19,901 : INFO : PROGRESS: pass 7, at document #1362/1362\n",
      "2021-06-05 17:03:20,341 : INFO : optimized alpha [0.07560976, 0.0666159, 0.08130715]\n",
      "2021-06-05 17:03:20,343 : INFO : topic #0 (0.076): 0.021*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"let\" + 0.013*\"shit\" + 0.013*\"love\" + 0.011*\"ft\" + 0.011*\"ain\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:20,344 : INFO : topic #1 (0.067): 0.018*\"mind\" + 0.014*\"got\" + 0.011*\"just\" + 0.011*\"way\" + 0.010*\"wanna\" + 0.010*\"tell\" + 0.010*\"day\" + 0.010*\"love\" + 0.010*\"cause\" + 0.009*\"long\"\n",
      "2021-06-05 17:03:20,344 : INFO : topic #2 (0.081): 0.015*\"ain\" + 0.012*\"love\" + 0.012*\"just\" + 0.011*\"baby\" + 0.011*\"got\" + 0.010*\"need\" + 0.010*\"que\" + 0.009*\"time\" + 0.008*\"young\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:20,345 : INFO : topic diff=0.073924, rho=0.333333\n",
      "2021-06-05 17:03:20,347 : INFO : PROGRESS: pass 8, at document #1362/1362\n",
      "2021-06-05 17:03:20,895 : INFO : optimized alpha [0.07277587, 0.065285124, 0.07780655]\n",
      "2021-06-05 17:03:20,897 : INFO : topic #0 (0.073): 0.021*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.013*\"love\" + 0.011*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:20,898 : INFO : topic #1 (0.065): 0.018*\"mind\" + 0.014*\"got\" + 0.012*\"just\" + 0.011*\"way\" + 0.010*\"love\" + 0.010*\"wanna\" + 0.010*\"tell\" + 0.010*\"day\" + 0.010*\"cause\" + 0.009*\"long\"\n",
      "2021-06-05 17:03:20,900 : INFO : topic #2 (0.078): 0.014*\"ain\" + 0.011*\"just\" + 0.011*\"baby\" + 0.011*\"love\" + 0.011*\"got\" + 0.011*\"need\" + 0.011*\"que\" + 0.009*\"time\" + 0.009*\"young\" + 0.008*\"good\"\n",
      "2021-06-05 17:03:20,900 : INFO : topic diff=0.064419, rho=0.316228\n",
      "2021-06-05 17:03:20,903 : INFO : PROGRESS: pass 9, at document #1362/1362\n",
      "2021-06-05 17:03:21,404 : INFO : optimized alpha [0.07041615, 0.064227045, 0.074582815]\n",
      "2021-06-05 17:03:21,405 : INFO : topic #0 (0.070): 0.021*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.013*\"love\" + 0.011*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"make\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-05 17:03:21,406 : INFO : topic #1 (0.064): 0.017*\"mind\" + 0.014*\"got\" + 0.012*\"just\" + 0.011*\"love\" + 0.011*\"way\" + 0.010*\"tell\" + 0.010*\"wanna\" + 0.010*\"day\" + 0.010*\"cause\" + 0.009*\"ain\"\n",
      "2021-06-05 17:03:21,407 : INFO : topic #2 (0.075): 0.014*\"ain\" + 0.011*\"baby\" + 0.011*\"just\" + 0.011*\"love\" + 0.011*\"got\" + 0.011*\"need\" + 0.011*\"que\" + 0.009*\"young\" + 0.009*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:21,408 : INFO : topic diff=0.056853, rho=0.301511\n",
      "2021-06-05 17:03:21,410 : INFO : PROGRESS: pass 10, at document #1362/1362\n",
      "2021-06-05 17:03:21,907 : INFO : optimized alpha [0.06848299, 0.063573465, 0.072007366]\n",
      "2021-06-05 17:03:21,907 : INFO : topic #0 (0.068): 0.021*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.013*\"love\" + 0.011*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"make\"\n",
      "2021-06-05 17:03:21,908 : INFO : topic #1 (0.064): 0.017*\"mind\" + 0.014*\"got\" + 0.012*\"just\" + 0.011*\"love\" + 0.011*\"way\" + 0.010*\"tell\" + 0.010*\"wanna\" + 0.010*\"day\" + 0.010*\"cause\" + 0.009*\"ain\"\n",
      "2021-06-05 17:03:21,908 : INFO : topic #2 (0.072): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"just\" + 0.011*\"que\" + 0.011*\"need\" + 0.011*\"got\" + 0.011*\"love\" + 0.009*\"young\" + 0.009*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:21,909 : INFO : topic diff=0.050104, rho=0.288675\n",
      "2021-06-05 17:03:21,912 : INFO : PROGRESS: pass 11, at document #1362/1362\n",
      "2021-06-05 17:03:22,412 : INFO : optimized alpha [0.066757664, 0.063535936, 0.06985906]\n",
      "2021-06-05 17:03:22,415 : INFO : topic #0 (0.067): 0.022*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.013*\"love\" + 0.011*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:22,415 : INFO : topic #1 (0.064): 0.017*\"mind\" + 0.015*\"got\" + 0.012*\"just\" + 0.012*\"love\" + 0.011*\"way\" + 0.010*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"day\" + 0.009*\"ain\"\n",
      "2021-06-05 17:03:22,416 : INFO : topic #2 (0.070): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"just\" + 0.011*\"que\" + 0.011*\"need\" + 0.010*\"got\" + 0.010*\"love\" + 0.009*\"young\" + 0.009*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:22,416 : INFO : topic diff=0.045383, rho=0.277350\n",
      "2021-06-05 17:03:22,418 : INFO : PROGRESS: pass 12, at document #1362/1362\n",
      "2021-06-05 17:03:22,858 : INFO : optimized alpha [0.0653003, 0.063455895, 0.06807252]\n",
      "2021-06-05 17:03:22,859 : INFO : topic #0 (0.065): 0.022*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:22,860 : INFO : topic #1 (0.063): 0.017*\"mind\" + 0.015*\"got\" + 0.012*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.010*\"day\"\n",
      "2021-06-05 17:03:22,860 : INFO : topic #2 (0.068): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"just\" + 0.011*\"que\" + 0.011*\"need\" + 0.010*\"got\" + 0.010*\"love\" + 0.009*\"young\" + 0.009*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:22,861 : INFO : topic diff=0.040346, rho=0.267261\n",
      "2021-06-05 17:03:22,863 : INFO : PROGRESS: pass 13, at document #1362/1362\n",
      "2021-06-05 17:03:23,292 : INFO : optimized alpha [0.064040616, 0.06333219, 0.06649623]\n",
      "2021-06-05 17:03:23,294 : INFO : topic #0 (0.064): 0.022*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:23,295 : INFO : topic #1 (0.063): 0.017*\"mind\" + 0.015*\"got\" + 0.013*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:23,295 : INFO : topic #2 (0.066): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"que\" + 0.011*\"just\" + 0.011*\"need\" + 0.010*\"got\" + 0.010*\"love\" + 0.009*\"young\" + 0.009*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:23,296 : INFO : topic diff=0.036404, rho=0.258199\n",
      "2021-06-05 17:03:23,298 : INFO : PROGRESS: pass 14, at document #1362/1362\n",
      "2021-06-05 17:03:23,707 : INFO : optimized alpha [0.06287197, 0.06317232, 0.065135345]\n",
      "2021-06-05 17:03:23,709 : INFO : topic #0 (0.063): 0.022*\"nigga\" + 0.019*\"got\" + 0.015*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:23,710 : INFO : topic #1 (0.063): 0.017*\"mind\" + 0.015*\"got\" + 0.013*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:23,710 : INFO : topic #2 (0.065): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"que\" + 0.011*\"need\" + 0.011*\"just\" + 0.010*\"got\" + 0.010*\"love\" + 0.009*\"young\" + 0.008*\"time\" + 0.008*\"nah\"\n",
      "2021-06-05 17:03:23,711 : INFO : topic diff=0.033037, rho=0.250000\n",
      "2021-06-05 17:03:23,713 : INFO : PROGRESS: pass 15, at document #1362/1362\n",
      "2021-06-05 17:03:24,120 : INFO : optimized alpha [0.061838128, 0.06298124, 0.06386204]\n",
      "2021-06-05 17:03:24,122 : INFO : topic #0 (0.062): 0.022*\"nigga\" + 0.020*\"got\" + 0.016*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:24,123 : INFO : topic #1 (0.063): 0.017*\"mind\" + 0.015*\"got\" + 0.013*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:24,124 : INFO : topic #2 (0.064): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"que\" + 0.011*\"need\" + 0.011*\"just\" + 0.010*\"got\" + 0.009*\"love\" + 0.009*\"young\" + 0.009*\"nah\" + 0.008*\"time\"\n",
      "2021-06-05 17:03:24,125 : INFO : topic diff=0.030152, rho=0.242536\n",
      "2021-06-05 17:03:24,128 : INFO : PROGRESS: pass 16, at document #1362/1362\n",
      "2021-06-05 17:03:24,551 : INFO : optimized alpha [0.060923915, 0.06277646, 0.06273782]\n",
      "2021-06-05 17:03:24,552 : INFO : topic #0 (0.061): 0.022*\"nigga\" + 0.020*\"got\" + 0.016*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"love\" + 0.012*\"ain\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:24,553 : INFO : topic #1 (0.063): 0.016*\"mind\" + 0.015*\"got\" + 0.014*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:24,554 : INFO : topic #2 (0.063): 0.014*\"ain\" + 0.012*\"baby\" + 0.011*\"que\" + 0.011*\"need\" + 0.011*\"just\" + 0.010*\"got\" + 0.009*\"young\" + 0.009*\"love\" + 0.009*\"nah\" + 0.008*\"time\"\n",
      "2021-06-05 17:03:24,555 : INFO : topic diff=0.027336, rho=0.235702\n",
      "2021-06-05 17:03:24,557 : INFO : PROGRESS: pass 17, at document #1362/1362\n",
      "2021-06-05 17:03:24,974 : INFO : optimized alpha [0.06011436, 0.06256897, 0.061775617]\n",
      "2021-06-05 17:03:24,976 : INFO : topic #0 (0.060): 0.022*\"nigga\" + 0.020*\"got\" + 0.016*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"ain\" + 0.012*\"love\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:24,976 : INFO : topic #1 (0.063): 0.016*\"mind\" + 0.015*\"got\" + 0.014*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:24,978 : INFO : topic #2 (0.062): 0.014*\"ain\" + 0.011*\"baby\" + 0.011*\"que\" + 0.011*\"need\" + 0.011*\"just\" + 0.009*\"got\" + 0.009*\"young\" + 0.009*\"love\" + 0.009*\"nah\" + 0.008*\"time\"\n",
      "2021-06-05 17:03:24,978 : INFO : topic diff=0.025082, rho=0.229416\n",
      "2021-06-05 17:03:24,980 : INFO : PROGRESS: pass 18, at document #1362/1362\n",
      "2021-06-05 17:03:25,394 : INFO : optimized alpha [0.0594072, 0.06250837, 0.06091821]\n",
      "2021-06-05 17:03:25,395 : INFO : topic #0 (0.059): 0.022*\"nigga\" + 0.020*\"got\" + 0.016*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"ain\" + 0.011*\"love\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n",
      "2021-06-05 17:03:25,395 : INFO : topic #1 (0.063): 0.016*\"mind\" + 0.015*\"got\" + 0.015*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"day\"\n",
      "2021-06-05 17:03:25,396 : INFO : topic #2 (0.061): 0.014*\"ain\" + 0.012*\"que\" + 0.011*\"baby\" + 0.011*\"need\" + 0.011*\"just\" + 0.009*\"got\" + 0.009*\"young\" + 0.009*\"love\" + 0.009*\"nah\" + 0.008*\"time\"\n",
      "2021-06-05 17:03:25,397 : INFO : topic diff=0.023281, rho=0.223607\n",
      "2021-06-05 17:03:25,399 : INFO : PROGRESS: pass 19, at document #1362/1362\n",
      "2021-06-05 17:03:25,828 : INFO : optimized alpha [0.058949936, 0.06246222, 0.060183086]\n",
      "2021-06-05 17:03:25,829 : INFO : topic #0 (0.059): 0.022*\"nigga\" + 0.020*\"got\" + 0.016*\"bitch\" + 0.013*\"shit\" + 0.013*\"let\" + 0.012*\"ain\" + 0.011*\"love\" + 0.011*\"ft\" + 0.009*\"anderson\" + 0.008*\"lil\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-05 17:03:25,830 : INFO : topic #1 (0.062): 0.016*\"mind\" + 0.015*\"got\" + 0.015*\"love\" + 0.012*\"just\" + 0.011*\"way\" + 0.011*\"tell\" + 0.010*\"wanna\" + 0.010*\"cause\" + 0.010*\"ain\" + 0.009*\"long\"\n",
      "2021-06-05 17:03:25,830 : INFO : topic #2 (0.060): 0.014*\"ain\" + 0.012*\"que\" + 0.011*\"baby\" + 0.011*\"need\" + 0.011*\"just\" + 0.009*\"young\" + 0.009*\"got\" + 0.009*\"nah\" + 0.009*\"love\" + 0.008*\"time\"\n",
      "2021-06-05 17:03:25,831 : INFO : topic diff=0.021719, rho=0.218218\n",
      "2021-06-05 17:03:25,833 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=2132, num_topics=3, decay=0.5, chunksize=2000) in 14.46s', 'datetime': '2021-06-05T17:03:25.832059', 'gensim': '4.0.1', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 3\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-05 17:03:25,875 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.8952.\n",
      "[([(0.016109781, 'mind'),\n",
      "   (0.015322884, 'got'),\n",
      "   (0.015135687, 'love'),\n",
      "   (0.0121295545, 'just'),\n",
      "   (0.011171913, 'way'),\n",
      "   (0.010941835, 'tell'),\n",
      "   (0.009910608, 'wanna'),\n",
      "   (0.009875395, 'cause'),\n",
      "   (0.00984214, 'ain'),\n",
      "   (0.009008761, 'long'),\n",
      "   (0.008997982, 'day'),\n",
      "   (0.008646027, 'time'),\n",
      "   (0.008575311, 'life'),\n",
      "   (0.008149193, 'good'),\n",
      "   (0.007898341, 'girl'),\n",
      "   (0.007887297, 'let'),\n",
      "   (0.007836657, 'make'),\n",
      "   (0.007789673, 'say'),\n",
      "   (0.0073592225, 'night'),\n",
      "   (0.007258794, 'right')],\n",
      "  -0.9151906930555305),\n",
      " ([(0.022344874, 'nigga'),\n",
      "   (0.019564088, 'got'),\n",
      "   (0.015909702, 'bitch'),\n",
      "   (0.013216442, 'shit'),\n",
      "   (0.01266304, 'let'),\n",
      "   (0.011929124, 'ain'),\n",
      "   (0.011274982, 'love'),\n",
      "   (0.011174873, 'ft'),\n",
      "   (0.008744023, 'anderson'),\n",
      "   (0.008187753, 'lil'),\n",
      "   (0.007881395, 'make'),\n",
      "   (0.007830005, 'just'),\n",
      "   (0.0074762865, 'come'),\n",
      "   (0.007122775, 'gon'),\n",
      "   (0.006424255, 'em'),\n",
      "   (0.0063777124, 'blrrrd'),\n",
      "   (0.0063680904, 'need'),\n",
      "   (0.0063001155, 'time'),\n",
      "   (0.0061058453, 'run'),\n",
      "   (0.0059529417, 'man')],\n",
      "  -2.067315025130716),\n",
      " ([(0.0135831125, 'ain'),\n",
      "   (0.011634207, 'que'),\n",
      "   (0.011444949, 'baby'),\n",
      "   (0.011328306, 'need'),\n",
      "   (0.010762866, 'just'),\n",
      "   (0.00938114, 'young'),\n",
      "   (0.009240836, 'got'),\n",
      "   (0.008757904, 'nah'),\n",
      "   (0.008579083, 'love'),\n",
      "   (0.008403117, 'time'),\n",
      "   (0.008225003, 'think'),\n",
      "   (0.007986637, 'lo'),\n",
      "   (0.0079852585, 'yo'),\n",
      "   (0.007851063, 'good'),\n",
      "   (0.007532928, 'friend'),\n",
      "   (0.007477417, 'make'),\n",
      "   (0.0073136464, 'let'),\n",
      "   (0.0063380506, 'bitch'),\n",
      "   (0.006275747, 'life'),\n",
      "   (0.006068884, 'si')],\n",
      "  -2.703237153372144)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
